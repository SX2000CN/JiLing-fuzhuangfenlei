"""
PyTorchåˆ†ç±»å™¨æ¨¡å—
è´Ÿè´£å›¾åƒåˆ†ç±»çš„æ ¸å¿ƒåŠŸèƒ½
"""

import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image
import numpy as np
from pathlib import Path
import shutil
import json
from typing import List, Dict, Tuple, Union, Optional
import logging
from tqdm import tqdm
import time

from .model_factory import ModelFactory

logger = logging.getLogger(__name__)


class ClothingClassifier:
    """æœè£…å›¾ç‰‡åˆ†ç±»å™¨"""
    
    def __init__(self, model_path: str, device: str = 'auto', model_name: str = 'efficientnetv2_s'):
        """
        åˆå§‹åŒ–åˆ†ç±»å™¨
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
            device: è®¡ç®—è®¾å¤‡ ('auto', 'cuda', 'cpu')
            model_name: æ¨¡å‹åç§°
        """
        self.device = self._setup_device(device)
        self.model_name = model_name
        self.model_path = model_path
        self.classes = ['ä¸»å›¾', 'ç»†èŠ‚', 'åŠç‰Œ']  # ç±»åˆ«åç§°
        self.num_classes = len(self.classes)
        
        # åŠ è½½æ¨¡å‹
        self.model = self._load_model()
        
        # è®¾ç½®å›¾åƒé¢„å¤„ç†
        self.transform = self._get_transform()
        
        logger.info(f"åˆ†ç±»å™¨åˆå§‹åŒ–å®Œæˆ:")
        logger.info(f"  - è®¾å¤‡: {self.device}")
        logger.info(f"  - æ¨¡å‹: {self.model_name}")
        logger.info(f"  - ç±»åˆ«: {self.classes}")
    
    def _setup_device(self, device: str) -> torch.device:
        """è®¾ç½®è®¡ç®—è®¾å¤‡"""
        if device == 'auto':
            if torch.cuda.is_available():
                device_name = torch.device('cuda')
                logger.info(f"è‡ªåŠ¨é€‰æ‹©GPU: {torch.cuda.get_device_name(0)}")
            else:
                device_name = torch.device('cpu')
                logger.info("GPUä¸å¯ç”¨ï¼Œä½¿ç”¨CPU")
        else:
            device_name = torch.device(device)
            logger.info(f"ä½¿ç”¨æŒ‡å®šè®¾å¤‡: {device}")
        
        return device_name
    
    def _load_model(self) -> nn.Module:
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        try:
            # åˆ›å»ºæ¨¡å‹ç»“æ„
            model = ModelFactory.create_model(
                self.model_name, 
                num_classes=self.num_classes, 
                pretrained=False
            )
            
            # åŠ è½½æƒé‡
            if Path(self.model_path).exists():
                logger.info(f"åŠ è½½æ¨¡å‹æƒé‡: {self.model_path}")
                checkpoint = torch.load(self.model_path, map_location=self.device)
                
                # å¤„ç†ä¸åŒçš„ä¿å­˜æ ¼å¼
                if 'model_state_dict' in checkpoint:
                    model.load_state_dict(checkpoint['model_state_dict'])
                    logger.info(f"åŠ è½½è®­ç»ƒä¿¡æ¯: epoch {checkpoint.get('epoch', 'unknown')}")
                else:
                    model.load_state_dict(checkpoint)
            else:
                logger.warning(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
                logger.warning("ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ï¼ŒæœªåŠ è½½è‡ªå®šä¹‰æƒé‡")
            
            # ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡å¹¶è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
            model.to(self.device)
            model.eval()
            
            logger.info("æ¨¡å‹åŠ è½½å®Œæˆ")
            return model
            
        except Exception as e:
            logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def _get_transform(self) -> transforms.Compose:
        """è·å–å›¾åƒé¢„å¤„ç†ç®¡é“"""
        # ä½¿ç”¨580x580å°ºå¯¸ï¼Œåœ¨512å’Œ600ä¹‹é—´å¯»æ‰¾æœ€ä½³ç”œèœœç‚¹
        input_size = 580  # æµ‹è¯•580ï¼Œæ¥è¿‘512å’Œ600çš„ä¸­é—´å€¼
        
        transform = transforms.Compose([
            transforms.Resize((input_size, input_size)),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],  # ImageNetæ ‡å‡†åŒ–
                std=[0.229, 0.224, 0.225]
            )
        ])
        
        logger.info(f"å›¾åƒé¢„å¤„ç†: ç”œèœœç‚¹è¾“å…¥å°ºå¯¸ {input_size}x{input_size}")
        return transform
    
    def predict_single(self, image_path: Union[str, Path]) -> Tuple[str, float, Dict]:
        """
        åˆ†ç±»å•å¼ å›¾ç‰‡
        
        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            
        Returns:
            Tuple[é¢„æµ‹ç±»åˆ«, ç½®ä¿¡åº¦, è¯¦ç»†ç»“æœ]
        """
        try:
            # åŠ è½½å’Œé¢„å¤„ç†å›¾åƒ
            image = Image.open(image_path).convert('RGB')
            input_tensor = self.transform(image).unsqueeze(0).to(self.device)
            
            # æ¨ç†
            with torch.no_grad():
                outputs = self.model(input_tensor)
                probabilities = torch.softmax(outputs, dim=1)
                confidence, predicted = torch.max(probabilities, 1)
                
                predicted_class = self.classes[predicted.item()]
                confidence_score = confidence.item()
                
                # æ‰€æœ‰ç±»åˆ«çš„æ¦‚ç‡
                all_probs = probabilities.cpu().numpy()[0]
                class_probs = {
                    class_name: float(prob) 
                    for class_name, prob in zip(self.classes, all_probs)
                }
            
            result = {
                'predicted_class': predicted_class,
                'confidence': confidence_score,
                'all_probabilities': class_probs,
                'image_path': str(image_path)
            }
            
            return predicted_class, confidence_score, result
            
        except Exception as e:
            logger.error(f"åˆ†ç±»å¤±è´¥ {image_path}: {e}")
            raise
    
    def classify_folder(self, 
                       input_folder: Union[str, Path], 
                       output_folder: Union[str, Path],
                       confidence_threshold: float = 0.5,
                       move_files: bool = True,
                       save_results: bool = True) -> Dict:
        """
        æ‰¹é‡åˆ†ç±»æ–‡ä»¶å¤¹ä¸­çš„å›¾ç‰‡
        
        Args:
            input_folder: è¾“å…¥æ–‡ä»¶å¤¹è·¯å¾„
            output_folder: è¾“å‡ºæ–‡ä»¶å¤¹è·¯å¾„
            confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            move_files: æ˜¯å¦ç§»åŠ¨æ–‡ä»¶ï¼ˆTrueç§»åŠ¨ï¼ŒFalseå¤åˆ¶ï¼‰
            save_results: æ˜¯å¦ä¿å­˜åˆ†ç±»ç»“æœ
            
        Returns:
            åˆ†ç±»ç»Ÿè®¡ç»“æœ
        """
        input_path = Path(input_folder)
        output_path = Path(output_folder)
        
        if not input_path.exists():
            raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {input_folder}")
        
        # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
        for class_name in self.classes:
            (output_path / class_name).mkdir(parents=True, exist_ok=True)
        
        # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}
        image_files = [
            f for f in input_path.iterdir() 
            if f.suffix.lower() in image_extensions and f.is_file()
        ]
        
        if not image_files:
            logger.warning(f"åœ¨ {input_folder} ä¸­æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
            return {'total': 0, 'processed': 0, 'failed': 0}
        
        logger.info(f"å¼€å§‹æ‰¹é‡åˆ†ç±»: {len(image_files)} å¼ å›¾ç‰‡")
        
        # åˆ†ç±»ç»Ÿè®¡
        stats = {
            'total': len(image_files),
            'processed': 0,
            'failed': 0,
            'by_class': {class_name: 0 for class_name in self.classes},
            'low_confidence': 0,
            'results': [],
            'start_time': time.time()
        }
        
        # æ‰¹é‡å¤„ç†
        for image_file in tqdm(image_files, desc="åˆ†ç±»ä¸­"):
            try:
                # åˆ†ç±»
                predicted_class, confidence, result = self.predict_single(image_file)
                
                # æ£€æŸ¥ç½®ä¿¡åº¦
                if confidence >= confidence_threshold:
                    # ç§»åŠ¨/å¤åˆ¶æ–‡ä»¶
                    dest_folder = output_path / predicted_class
                    dest_file = dest_folder / image_file.name
                    
                    if move_files:
                        shutil.move(str(image_file), str(dest_file))
                    else:
                        shutil.copy2(str(image_file), str(dest_file))
                    
                    stats['by_class'][predicted_class] += 1
                    stats['processed'] += 1
                    
                    logger.debug(f"âœ… {image_file.name} â†’ {predicted_class} ({confidence:.2%})")
                else:
                    stats['low_confidence'] += 1
                    logger.warning(f"âš ï¸ {image_file.name}: ç½®ä¿¡åº¦è¿‡ä½ ({confidence:.2%})")
                
                # ä¿å­˜ç»“æœ
                if save_results:
                    stats['results'].append(result)
                
            except Exception as e:
                stats['failed'] += 1
                logger.error(f"âŒ å¤„ç†å¤±è´¥ {image_file.name}: {e}")
        
        # è®¡ç®—è€—æ—¶
        stats['processing_time'] = time.time() - stats['start_time']
        stats['speed'] = stats['total'] / stats['processing_time']  # å¼ /ç§’
        
        # ä¿å­˜ç»Ÿè®¡ç»“æœ
        if save_results:
            self._save_classification_report(output_path, stats)
        
        self._print_summary(stats)
        return stats
    
    def batch_predict(self, image_paths: List[Union[str, Path]], batch_size: int = 32) -> List[Dict]:
        """
        æ‰¹é‡é¢„æµ‹ï¼ˆä¸ç§»åŠ¨æ–‡ä»¶ï¼‰
        
        Args:
            image_paths: å›¾ç‰‡è·¯å¾„åˆ—è¡¨
            batch_size: æ‰¹æ¬¡å¤§å°
            
        Returns:
            é¢„æµ‹ç»“æœåˆ—è¡¨
        """
        results = []
        
        logger.info(f"æ‰¹é‡é¢„æµ‹: {len(image_paths)} å¼ å›¾ç‰‡")
        
        for i in tqdm(range(0, len(image_paths), batch_size), desc="é¢„æµ‹ä¸­"):
            batch_paths = image_paths[i:i + batch_size]
            
            for image_path in batch_paths:
                try:
                    predicted_class, confidence, result = self.predict_single(image_path)
                    results.append(result)
                except Exception as e:
                    logger.error(f"é¢„æµ‹å¤±è´¥ {image_path}: {e}")
                    results.append({
                        'predicted_class': 'unknown',
                        'confidence': 0.0,
                        'error': str(e),
                        'image_path': str(image_path)
                    })
        
        return results
    
    def _save_classification_report(self, output_folder: Path, stats: Dict):
        """ä¿å­˜åˆ†ç±»æŠ¥å‘Š"""
        report_file = output_folder / f"classification_report_{int(time.time())}.json"
        
        # ç®€åŒ–statsç”¨äºJSONåºåˆ—åŒ–
        simple_stats = {
            'summary': {
                'total_images': stats['total'],
                'processed': stats['processed'],
                'failed': stats['failed'],
                'low_confidence': stats['low_confidence'],
                'processing_time': f"{stats['processing_time']:.2f}s",
                'speed': f"{stats['speed']:.1f} images/sec"
            },
            'by_class': stats['by_class'],
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'model_info': {
                'model_name': self.model_name,
                'model_path': self.model_path,
                'device': str(self.device)
            }
        }
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(simple_stats, f, ensure_ascii=False, indent=2)
        
        logger.info(f"åˆ†ç±»æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
    
    def _print_summary(self, stats: Dict):
        """æ‰“å°åˆ†ç±»æ‘˜è¦"""
        print("\n" + "="*50)
        print("ğŸ“Š åˆ†ç±»ç»“æœæ‘˜è¦")
        print("="*50)
        print(f"æ€»å›¾ç‰‡æ•°é‡: {stats['total']}")
        print(f"æˆåŠŸå¤„ç†: {stats['processed']}")
        print(f"å¤„ç†å¤±è´¥: {stats['failed']}")
        print(f"ç½®ä¿¡åº¦è¿‡ä½: {stats['low_confidence']}")
        print(f"å¤„ç†æ—¶é—´: {stats['processing_time']:.2f}ç§’")
        print(f"å¤„ç†é€Ÿåº¦: {stats['speed']:.1f}å¼ /ç§’")
        print("\nğŸ“‹ å„ç±»åˆ«ç»Ÿè®¡:")
        for class_name, count in stats['by_class'].items():
            percentage = (count / stats['total'] * 100) if stats['total'] > 0 else 0
            print(f"  {class_name}: {count}å¼  ({percentage:.1f}%)")
        print("="*50)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    import logging
    logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')
    
    print("ğŸ§ª æµ‹è¯•åˆ†ç±»å™¨...")
    
    # æ³¨æ„ï¼šè¿™éœ€è¦ä¸€ä¸ªå®é™…çš„æ¨¡å‹æ–‡ä»¶æ‰èƒ½å®Œå…¨æµ‹è¯•
    try:
        # åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿæ¨¡å‹ç”¨äºæµ‹è¯•ï¼ˆä»…æµ‹è¯•ç»“æ„ï¼‰
        model_path = "test_model.pth"
        
        # ä¿å­˜ä¸€ä¸ªç®€å•çš„æ¨¡å‹ç”¨äºæµ‹è¯•
        test_model = ModelFactory.create_model('efficientnetv2_s', num_classes=3, pretrained=False)
        torch.save(test_model.state_dict(), model_path)
        
        # æµ‹è¯•åˆ†ç±»å™¨åˆå§‹åŒ–
        classifier = ClothingClassifier(model_path, device='cpu')
        print("âœ… åˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        Path(model_path).unlink()
        print("âœ… æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
