#!/usr/bin/env python3
"""
JiLingæœè£…åˆ†ç±»ç³»ç»Ÿ - å‘½ä»¤è¡Œç‰ˆæœ¬
ç›´æŽ¥ä½¿ç”¨GUIä¿å­˜çš„è®¾ç½®è¿›è¡Œåˆ†ç±»ï¼Œæ— éœ€GUIç•Œé¢
"""

import sys
import os
import json
import time
import torch
from pathlib import Path
from typing import List
from PIL import Image
from tqdm import tqdm
import concurrent.futures

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

try:
    from PySide6.QtCore import QSettings
    from PySide6.QtWidgets import QApplication
    from src.core.pytorch_classifier import ClothingClassifier
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿å·²å®‰è£…PySide6å’Œç›¸å…³ä¾èµ–")
    sys.exit(1)


class CommandLineClassifier:
    """å‘½ä»¤è¡Œåˆ†ç±»å™¨"""
    
    def __init__(self):
        # åˆ›å»ºQApplicationï¼ˆå¿…éœ€ï¼Œå³ä½¿ä¸æ˜¾ç¤ºGUIï¼‰
        self.app = QApplication.instance()
        if self.app is None:
            self.app = QApplication([])
        
        # åˆå§‹åŒ–è®¾ç½®
        self.settings = QSettings("JiLing", "ClothingClassifier")
        self.classifier = None
        
    def load_gui_settings(self):
        """åŠ è½½GUIä¸­ä¿å­˜çš„è®¾ç½®"""
        print("ðŸ“‚ åŠ è½½GUIè®¾ç½®...")
        
        # èŽ·å–è®°å¿†çš„è·¯å¾„
        self.classification_folder = self.settings.value("last_classification_folder", "")
        self.model_folder = self.settings.value("last_model_folder", "models")
        
        print(f"  ä¸Šæ¬¡åˆ†ç±»è·¯å¾„: {self.classification_folder}")
        print(f"  æ¨¡åž‹æ–‡ä»¶å¤¹: {self.model_folder}")
        
        return bool(self.classification_folder and os.path.exists(self.classification_folder))
    
    def find_latest_model(self):
        """æŸ¥æ‰¾æœ€æ–°çš„JiLing_baidituæ¨¡åž‹"""
        models_dir = Path("models")
        if not models_dir.exists():
            return None
        
        # æŸ¥æ‰¾JiLing_baidituæ¨¡åž‹æ–‡ä»¶
        jiling_models = list(models_dir.glob("JiLing_baiditu_*.pth"))
        if jiling_models:
            # æŒ‰æ—¶é—´æˆ³æŽ’åºï¼ŒèŽ·å–æœ€æ–°çš„
            latest_model = max(jiling_models, key=lambda x: x.stat().st_mtime)
            return str(latest_model)
        
        # å›žé€€åˆ°å…¶ä»–æ¨¡åž‹
        other_models = list(models_dir.glob("*.pth"))
        if other_models:
            return str(other_models[0])
        
        return None
    
    def initialize_classifier(self):
        """åˆå§‹åŒ–åˆ†ç±»å™¨"""
        print("ðŸ¤– åˆå§‹åŒ–åˆ†ç±»å™¨...")
        
        # æŸ¥æ‰¾æ¨¡åž‹æ–‡ä»¶
        model_path = self.find_latest_model()
        if not model_path:
            print("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„æ¨¡åž‹æ–‡ä»¶")
            return False
        
        print(f"  ä½¿ç”¨æ¨¡åž‹: {model_path}")
        
        try:
            # åˆ›å»ºåˆ†ç±»å™¨ï¼Œä½¿ç”¨æ­£ç¡®çš„é…ç½®
            self.classifier = ClothingClassifier(
                model_path=model_path,
                model_name='tf_efficientnetv2_s',  # ä½¿ç”¨æ­£ç¡®çš„æ¨¡åž‹åç§°
                device='auto'
            )
            print("âœ… åˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"âŒ åˆ†ç±»å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def get_image_files(self, folder_path: str) -> List[str]:
        """èŽ·å–æ–‡ä»¶å¤¹ä¸­çš„å›¾åƒæ–‡ä»¶"""
        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}
        image_files = []
        
        folder = Path(folder_path)
        for file in folder.iterdir():
            if file.is_file() and file.suffix.lower() in image_extensions:
                image_files.append(str(file))
        
        return sorted(image_files)
    
    def _batch_predict_optimized(self, image_files: List[str], batch_size: int) -> List[dict]:
        """
        ä½¿ç”¨ä¸ŽGUIç›¸åŒçš„é«˜æ€§èƒ½æ‰¹é‡æŽ¨ç†æ–¹æ³•
        """
        results = []
        total_files = len(image_files)
        
        # åˆ†æ‰¹å¤„ç†
        for batch_start in range(0, total_files, batch_size):
            batch_end = min(batch_start + batch_size, total_files)
            batch_paths = image_files[batch_start:batch_end]
            
            print(f"ðŸ“¦ å¤„ç†æ‰¹æ¬¡ {batch_start//batch_size + 1}, å›¾ç‰‡: {batch_start+1}-{batch_end}")
            
            # æ‰¹é‡é¢„å¤„ç†å›¾åƒ - å¤šçº¿ç¨‹å¹¶è¡Œä¼˜åŒ–
            preprocess_start = time.time()
            batch_tensors = []
            valid_paths = []
            
            def preprocess_single_image(image_path):
                try:
                    # ä½¿ç”¨PIL + åŽŸç”Ÿtransform - æœ€ä½³æ€§èƒ½å¹³è¡¡
                    image = Image.open(image_path).convert('RGB')
                    input_tensor = self.classifier.transform(image)
                    return image_path, input_tensor
                except Exception as e:
                    return image_path, None, str(e)
            
            # 20çº¿ç¨‹ - ç»è¿‡ç³»ç»Ÿæµ‹è¯•éªŒè¯çš„æœ€ä¼˜é…ç½® (29.48å¼ /ç§’)
            optimal_workers = 20
            
            print(f"ðŸš€ å¯ç”¨{optimal_workers}çº¿ç¨‹æœ€ä¼˜é…ç½®")
            
            with concurrent.futures.ThreadPoolExecutor(max_workers=optimal_workers) as executor:
                parallel_results = list(executor.map(preprocess_single_image, batch_paths))
            
            # æ”¶é›†æˆåŠŸå¤„ç†çš„ç»“æžœ
            for result in parallel_results:
                if len(result) == 2:  # æˆåŠŸ
                    image_path, tensor = result
                    batch_tensors.append(tensor)
                    valid_paths.append(image_path)
                else:  # å¤±è´¥
                    image_path, _, error = result
                    print(f"é¢„å¤„ç†å¤±è´¥ {image_path}: {error}")
                    results.append({
                        'predicted_class': 'unknown',
                        'confidence': 0.0,
                        'error': error,
                        'image_path': str(image_path)
                    })
            
            preprocess_end = time.time()
            preprocess_time = preprocess_end - preprocess_start
            print(f"â±ï¸ æ‰¹æ¬¡é¢„å¤„ç†å®Œæˆï¼Œ{len(batch_tensors)}å¼ å›¾ç‰‡ï¼Œè€—æ—¶: {preprocess_time:.3f}ç§’")
            
            if not batch_tensors:
                continue
            
            # é«˜æ•ˆGPUæŽ¨ç† - ä¸“æ³¨äºŽé€Ÿåº¦ä¼˜åŒ–
            inference_start = time.time()
            try:
                batch_tensor = torch.stack(batch_tensors).to(self.classifier.device, non_blocking=True)
                
                # å•è½®é«˜æ•ˆæŽ¨ç†ï¼Œä¸“æ³¨äºŽé€Ÿåº¦è€ŒéžGPUå ç”¨çŽ‡
                with torch.no_grad():
                    with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):
                        outputs = self.classifier.model(batch_tensor)
                        probabilities = torch.softmax(outputs, dim=1)
                        confidences, predicted = torch.max(probabilities, 1)
                
                inference_end = time.time()
                inference_time = inference_end - inference_start
                print(f"â±ï¸ GPUæŽ¨ç†å®Œæˆï¼Œ{len(batch_tensors)}å¼ å›¾ç‰‡ï¼Œè€—æ—¶: {inference_time:.3f}ç§’")
                
                # å¤„ç†æ‰¹é‡ç»“æžœ
                for i, (image_path, confidence, predicted_idx) in enumerate(zip(valid_paths, confidences, predicted)):
                    predicted_class = self.classifier.classes[predicted_idx.item()]
                    confidence_score = confidence.item()
                    
                    results.append({
                        'predicted_class': predicted_class,
                        'confidence': confidence_score,
                        'image_path': str(image_path)
                    })
                
                # æ¸…ç†GPUå†…å­˜
                del batch_tensor, outputs, probabilities
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    
            except Exception as e:
                print(f"æ‰¹é‡æŽ¨ç†å¤±è´¥: {e}")
                # é™çº§åˆ°å•å¼ å¤„ç†
                for image_path in valid_paths:
                    try:
                        predicted_class, confidence, result = self.classifier.predict_single(image_path)
                        results.append(result)
                    except Exception as e2:
                        results.append({
                            'predicted_class': 'unknown',
                            'confidence': 0.0,
                            'error': str(e2),
                            'image_path': str(image_path)
                        })
        
        return results
    
    def classify_images(self, image_files: List[str]):
        """åˆ†ç±»å›¾åƒ"""
        if not image_files:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å›¾åƒæ–‡ä»¶")
            return
        
        total_files = len(image_files)
        print(f"ðŸ“Š å¼€å§‹åˆ†ç±» {total_files} å¼ å›¾ç‰‡...")
        print("=" * 60)
        
        # åˆ›å»ºè¾“å‡ºç›®å½• - ä½¿ç”¨å›¾ç‰‡æ‰€åœ¨æ–‡ä»¶å¤¹çš„çˆ¶ç›®å½•ï¼ˆä¸ŽGUIç‰ˆæœ¬ä¸€è‡´ï¼‰
        input_folder = Path(self.classification_folder)
        base_dir = input_folder.parent  # ä½¿ç”¨çˆ¶ç›®å½•ä½œä¸ºè¾“å‡ºæ ¹ç›®å½•
        output_dirs = {
            'ä¸»å›¾': base_dir / 'ä¸»å›¾',
            'ç»†èŠ‚': base_dir / 'ç»†èŠ‚', 
            'åŠç‰Œ': base_dir / 'åŠç‰Œ'
            # ç§»é™¤unknownæ–‡ä»¶å¤¹ï¼Œä¸ŽGUIç‰ˆæœ¬ä¿æŒä¸€è‡´
        }
        
        for dir_path in output_dirs.values():
            dir_path.mkdir(exist_ok=True)
        
        # åˆ†ç±»ç»Ÿè®¡
        stats = {'ä¸»å›¾': 0, 'ç»†èŠ‚': 0, 'åŠç‰Œ': 0}
        start_time = time.time()
        
        try:
            # GPUä¼˜åŒ–æ‰¹é‡å¤„ç† - ä½¿ç”¨ä¸ŽGUIç›¸åŒçš„ç­–ç•¥
            if torch.cuda.is_available():
                gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)
                if gpu_memory_gb >= 10:  # RTX 3060 12GB
                    base_batch_size = 160  # å¢žå¤§æ‰¹æ¬¡ï¼Œæå‡GPUåˆ©ç”¨çŽ‡
                elif gpu_memory_gb >= 6:
                    base_batch_size = 128
                else:
                    base_batch_size = 64
                
                if total_files < base_batch_size:
                    batch_size = min(base_batch_size, total_files)
                else:
                    batch_size = base_batch_size
            else:
                batch_size = 32  # CPUæ¨¡å¼é™çº§
            
            print(f"â­ GPUä¼˜åŒ–æ¨¡å¼ - æ‰¹æ¬¡å¤§å° {batch_size} (GPU: {gpu_memory_gb:.1f}GB)")
            
            # ä½¿ç”¨ä¼˜åŒ–çš„æ‰¹é‡æŽ¨ç†æ–¹æ³•ï¼ˆä¸ŽGUIç›¸åŒï¼‰
            batch_results = self._batch_predict_optimized(image_files, batch_size)
            
            # å¤„ç†ç»“æžœå¹¶ç§»åŠ¨æ–‡ä»¶
            for i, result in enumerate(batch_results):
                image_path = image_files[i]
                file_name = Path(image_path).name
                predicted_class = result.get('predicted_class', 'unknown')
                confidence = result.get('confidence', 0.0)
                
                # ç§»åŠ¨æ–‡ä»¶
                source = Path(image_path)
                if predicted_class in output_dirs:
                    target = output_dirs[predicted_class] / file_name
                    if source != target:
                        source.rename(target)
                    # æ›´æ–°ç»Ÿè®¡
                    stats[predicted_class] += 1
                else:
                    # å¦‚æžœé¢„æµ‹ç±»åˆ«ä¸åœ¨å·²çŸ¥ç±»åˆ«ä¸­ï¼Œè·³è¿‡ç§»åŠ¨ä½†æ˜¾ç¤ºè­¦å‘Š
                    print(f"âš ï¸ æœªçŸ¥ç±»åˆ«: {predicted_class}ï¼Œè·³è¿‡ç§»åŠ¨ {file_name}")
                    continue
                
                # æ˜¾ç¤ºè¿›åº¦
                progress = (i + 1) / total_files * 100
                print(f"ðŸ“¦ [{progress:5.1f}%] {file_name} â†’ {predicted_class} ({confidence:.2f})")
        
        except KeyboardInterrupt:
            print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­åˆ†ç±»")
            return
        except Exception as e:
            print(f"\nâŒ åˆ†ç±»è¿‡ç¨‹å‡ºé”™: {e}")
            return
        
        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        elapsed_time = time.time() - start_time
        speed = total_files / elapsed_time
        
        print("=" * 60)
        print("ðŸŽ‰ åˆ†ç±»å®Œæˆ!")
        print(f"ðŸ“Š åˆ†ç±»ç»Ÿè®¡:")
        for category, count in stats.items():
            percentage = count / total_files * 100
            print(f"  {category}: {count} å¼  ({percentage:.1f}%)")
        
        print(f"â±ï¸ æ€»è€—æ—¶: {elapsed_time:.2f} ç§’")
        print(f"âš¡ å¹³å‡é€Ÿåº¦: {speed:.2f} å¼ /ç§’")
        print("=" * 60)
    
    def run(self):
        """è¿è¡Œåˆ†ç±»"""
        print("ðŸš€ JiLingæœè£…åˆ†ç±»ç³»ç»Ÿ - å‘½ä»¤è¡Œç‰ˆæœ¬")
        print("=" * 60)
        
        # åŠ è½½è®¾ç½®
        if not self.load_gui_settings():
            print("âŒ æœªæ‰¾åˆ°GUIä¿å­˜çš„è·¯å¾„è®¾ç½®")
            print("è¯·å…ˆåœ¨GUIä¸­é€‰æ‹©å¹¶ä½¿ç”¨ä¸€æ¬¡åˆ†ç±»åŠŸèƒ½")
            self.wait_for_exit()
            return
        
        # æ£€æŸ¥è·¯å¾„
        if not os.path.exists(self.classification_folder):
            print(f"âŒ åˆ†ç±»è·¯å¾„ä¸å­˜åœ¨: {self.classification_folder}")
            self.wait_for_exit()
            return
        
        # åˆå§‹åŒ–åˆ†ç±»å™¨
        if not self.initialize_classifier():
            self.wait_for_exit()
            return
        
        # èŽ·å–å›¾åƒæ–‡ä»¶
        image_files = self.get_image_files(self.classification_folder)
        if not image_files:
            print(f"âŒ åœ¨è·¯å¾„ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶: {self.classification_folder}")
            self.wait_for_exit()
            return
        
        # å¼€å§‹åˆ†ç±»
        self.classify_images(image_files)
        
        # ç­‰å¾…ç”¨æˆ·æŒ‰å›žè½¦é€€å‡º
        self.wait_for_exit()
    
    def wait_for_exit(self):
        """ç­‰å¾…ç”¨æˆ·æŒ‰å›žè½¦é€€å‡º"""
        print("\nðŸ’¡ æŒ‰å›žè½¦é”®é€€å‡º...")
        try:
            input()
        except KeyboardInterrupt:
            pass
        print("ðŸ‘‹ å†è§!")


def main():
    """ä¸»å‡½æ•°"""
    try:
        classifier = CommandLineClassifier()
        classifier.run()
    except KeyboardInterrupt:
        print("\nðŸ‘‹ ç”¨æˆ·å–æ¶ˆï¼Œå†è§!")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå¼‚å¸¸: {e}")
        print("ðŸ’¡ æŒ‰å›žè½¦é”®é€€å‡º...")
        try:
            input()
        except KeyboardInterrupt:
            pass


if __name__ == "__main__":
    main()
